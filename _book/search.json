[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pkpd notes",
    "section": "",
    "text": "Preface\nThis page is from index page"
  },
  {
    "objectID": "WinNonlinIntro.html#project-setup",
    "href": "WinNonlinIntro.html#project-setup",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.1 Project setup",
    "text": "1.1 Project setup\n\nCreate Project\n\nPhenoex Projects\n\ncontains all the data and calculations\nmultiple projects can be open at the same time\ncommon data file to import: excel, csv\nolder version can always be opened by newer version\nnewer version projects can not be opened by older ones\nCreate a project\nClick to history tab to see the project history\nClick to properties tab, where most of the work is done\n\n\nCreate Worksheets\n\n\nRight click on Data, select New, select Worksheet\nAdd columns, give column name, assign data type\nassign units: select time from list of columns, click Unit Builder button, specify h to the time, click Add button,click OK\nfor dose, specify mass prefex, click Add\nType numbers on the worksheet to add values to the cells\n\n\nImport Files\n\n\nfile type: xls, xlsx, csv, SAS\ntypical data file contains header and unit row.\nSelect the Import button, select the file\non the File import wizard, select appropriate options\nPreview area helps to see the changes\nIf units are in the column header, select “has units in the header”\n\nExcels with multiple worksheet:\n\nclick the arrow to move on the Wizard to the next worksheet\n\n\nSave Projects\n\n\nClick the save icon on the toolbar\nFile name can be completely different from the Project name\nNo auto-save options\nsharing project file will also share the embedded data files\nClose project by right clicking the project name\nAfter opening a saved project folder, expand the plus sign to see the contents.\n\n\nSet Project Preferences\n\n\nSelect the Edit menu -> preferences -> Projects\nCheck Autosave on execution\nupdate the save locations and hit apply before clicking on OK."
  },
  {
    "objectID": "WinNonlinIntro.html#create-and-modify-worksheets",
    "href": "WinNonlinIntro.html#create-and-modify-worksheets",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.2 Create and Modify Worksheets",
    "text": "1.2 Create and Modify Worksheets\n\nSort Rows\n\n\ndata can be sorted by subject, dose level,\nsort button on every worksheet\nUse the “sort worksheet” window to apply sort options\n\n\nMove Columns\n\n\nSelect a column from the column list\nClick the up or down arrow to move\n\n\nRename Columns\n\n\nClick the column name, type F2 or double click on it to edit the name\n\n\nApply Units\n\n\nSelect column\nClick the Unit Builder\nClick Clear Units\nAdd units\n\n\nConvert Units\n\n\nconvert amount column from microgram to miligram\nclick the Amount column\ntype mg in the New unit box,click OK\nTo convert ng/mL to nmole/mL, add nmol and then click the slash button, specify the volume unit, enter molecular weight, click OK.\nBetter way: use the Data Wizard to convert the units."
  },
  {
    "objectID": "WinNonlinIntro.html#plot-data",
    "href": "WinNonlinIntro.html#plot-data",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.3 Plot Data",
    "text": "1.3 Plot Data\n\nCreate Simple Plot\n\n\nData: Conc, Time, dose level: 16 mg, 10 subjects\nright click the worksheet\nSelect send to -> plotting -> xy plot\nXY object is created with the linked data source\nOn the mapping window, orange column headers are required mappings\nmap, x -> Time, y -> conc, Group -> subject\nclick execute\nOptions pan - Axes - Y - select log button\nOptions pan - Graphs - rename by typing F2\nGraph name and legend names are the same\n\n\nCreate Lattice Plot\n\n\nData: Conc, Time, Administration, dose level 4 mg for IV, 8 mg for PO, 10 subjects\nCreate a XY plot object same as above\nmap x - Time, y - conc, group - subject, lattice column - administration\nExecute and get two plots\nOptions - range - ‘auto scale best’ settings scales individual plots are independent\n\n\nUse Second Y Axis\n\n\nData: plasma conc, urine conc, time, 10 subjects\nCreat XY plot object same as above\nmap x - Time, y - plasma conc, y2 - urine conc, lattice condition, page (sort) - Subject\nplots are on a single page for each subject\nOptions - select plasma_conc vs Time, type F2, change the name to Plasma, do the same for Urine\nExecute\n\n\nCompute Descriptive Statistics\n\n\nNeeded to create a plot with mean and error bars\nright click on data sheet, send to - computation tools - Discriptive statistics\nmap summary - conc, sort - Time\nExecute\nOptions pannel - click Clear All - click basic statistics, check Mean and SD\n\n\nUse Error Bars\n\n\nDiscriptive Satistics object - Output data - right click on Statistics\nsend to plotting - XY plot\nmap x - Time, y - Mean, Error bars, lower - SD, Error bars, upper - SD\nExecute\nset Y axis to log scale\n\n\nCreate Overlay Plot\n\n\nduplicate the error bars plot from previous section\nOptions pan - Plot - Graphs tab - click Add button\nSelect the new second input from the setup tab\nLink the source data by clicking source button,\nmap x - Time, y - conc, group - subject\nExecute\nOptions pan - select Conc vs Time plot\nSelect Quick Styles\nUncheck Group by lines, uncheck Gourp by colors,\nSelect Apprance tab\nSpecify color to Silver\nUncheck Markers visible\nNow all the individual lines are silver color\nSelect Mean vs Time graph\nSelect Appearance, specify line colors to red, Marker border color - red, line weight 3\nUnder the Mean vs Time graph, select the Error bars\nSelect Appearance, color - red\nOptions pan - select Y axis - select Axis label and update\nOptions pan - select Legend - uncheck Visible\n\n\nCreate Box Plot\n\n\n\n\n\n\n\n20 subjects, AR: accumulation ratio (how much accumulated under repeated ss), dose level, 2 mg and 4 mg\nIs AR increases with increasing dose level?\nright click data, send to - plotting - box plot\nmap y - AR, group - dose level\nExecute\n\n\nCreate Plot with Categorical X Axis\n\n\nData: Severity (Mild, Moderate), dose level (1, 2, 4, 8, 16, 32 mg), frequency (numerical, i.e., 0, 0.2, 0.6)\nright click the data sheet, send to plotting - X-categorical XY plot\nmap x - severity, y - frequency, group - dose level\nOptions pan, select X axis, select Order tab, change order if needed\nOptions pan - Frequency vs Severity graph - check line visible - now points are connected by a line\n\n\nSet Plot Preferences\n\n\nOptions pan - Plot - Layout \nEdit menu bar, preferences, plotting details\nChanging prefernences affect all new plots"
  },
  {
    "objectID": "WinNonlinIntro.html#introduction-to-nca",
    "href": "WinNonlinIntro.html#introduction-to-nca",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.4 Introduction to NCA",
    "text": "1.4 Introduction to NCA\n\n1.4.1 About NCA\nNon-compartmental analysis or NCA is a method for quantifying drug exposure\n\nNCA determines a large number of pharmacokinetic descriptors or PK parameters for a drug\nThey are not really parameters as you would have in a model\nNCA does not use any kind of model other than assuming that the elimination can be described by first order kinetics\nbecause there is no model at the heart of the method we cannot really use it for predictions\nAn example plot of concentration over time following an extravascular dose NCA will give us two different measures of drug exposure:\n\nthe peak exposure to the drug concentration occurring after dosing\nThe overall exposure is measured by computing the area under the curve or AUC\nan extra vascular dose starts with a concentration of zero, the concentration rises rapidly reaches Cmax and then decreases\n\n\nwith extra vascular dosing there is an absorption process that leads to a maximum concentration followed by elimination\nIV bolus dosing: drug is directly injected all at once into a vein; the mixing and systemic circulation is very fast and by the time the first sample is taken after dosing the mixing is assumed to be complete. The concentration starts high and then decreases as the drug is eliminated.\nIV infusion: the concentration starts at zero and then rises if the infusion is continued for long enough the concentration approaches a plateau at steady state when the infusion stops the concentration then falls in the same manner as in ivy bolus dosing\nplotting on a log scale is useful because it usually shows linear elimination in each case regardless of the dosing root we could fit the linear portion with a straight line to predict what will happen to concentration after we’ve collected the last sample concentration on the log axis\n\n\n\nIt is useful to have both linear and log plots. Linear plots are useful for examining the peak concentration and log plots are useful for the low concentrations\nIn addition to an elimination phase many drugs also show a distribution phase in such cases there may be two distinctive straight line sections on the plot. Although sometimes the two phases blend into a general curvature in the plots we see here the distribution phase is apparent for all three dosing routs but it is most pronounced for the IV bolus dosing. For extravascular dosing the distribution phase may be obscured by the drug absorption.\nThe AUC can be determined no matter how complex the relationship between concentration and time.\nSummary:\nNCA is the primary method of assessing drug exposure.\nCmax is a measure of peak exposure\nAUC is a measure of the overall exposure to the drug\ndifferent dosing route leads to a curve with the distinctive shape that plotting on a log concentration scale usually shows linear elimination\nmany drugs show a distribution phase as well as an elimination phase\n\n\n\n\n1.4.2 Observe Parameters\n\nFrom the plot of concentration versus time, we can see that the maximum concentration is reached at about 1 hour, we call that time Tmax and the concentration at the peak is Cmax\nTmax and Cmax are listed in the output of NCA in Phoenix\nAt some point after dosing we will have our last observed concentration this may be because we have stopped collecting samples or the concentration may have dropped below the quantification limit for the analysis and therefore we were unable to get more values The point is at a time of t last and has a concentration of Tlast These observeed parameters are affected by the sampling schedule we can improve our chances by sampling richly around the expected time of c max if we have more points we have a better chance of capturing a concentration that is near the true maximum\n\nSummarize\n\nObserved parameters are TMax Cmax TLast and Clast. We call these observed parameters because they are found directly in the observations\nthe observed parameters are dependent on sampling times\nsample richly around the expected time of Cmax so you can have a better chance of capturing something close to the true maximum\n\n\n\n1.4.3 Half-Life\n\ntime it takes for the concentration to decrease by 50%.\na long half-life leads to a shallower slope and a short half-life leads to a steeper slope\nsome drugs exhibit two phases a distribution phase and an elimination phase each of these will have a half-life associated with it The shorter the half-life of the distribution phase the steeper the initial decline will be although we usually concentrate on the half-life of the elimination phase the effective half-life of the drug may very well depend on the half-lives of both of these processes\nIt takes five to seven half lives to eliminate the drug.\n\n\n\n1.4.4 Area Under the Curve (AUC)\nHow to calculate AUC?\n\nassume that the concentration follows a straight line between points\none triangle and several trapizoid\nAUC is calculated from concentration-time data\nTrapezoids are used to estimate AUC between two data points\nAUC is the sum of the areas of all the trapezoids plus one triangle\n\n\n\n1.4.5 Extrapolation to Infinity\n\nafter the Tlast there are still large quantity of drug in the plasma\nHow can we extrapolate to infinity?\nWe need a way to calculate the AUC Tlast - infinity.\nSlope of the elimination is the key, apparent terminal phase, magnitide of the slope is \\(\\lambda_Z\\)\n\n\\[\nAUC _{tlast - \\infty} = \\frac{C_{last}}{\\lambda_z}\n\\]\n\\[\nAUC _{0 - \\infty} = AUC_{last} + \\frac{C_{last}}{\\lambda_z}\n\\]\n\nextrapolatd area should be below 20%\n\nImportant NCA parameters:\n\nIndependent of least\nsquares fit, such as Cmax, Tmax, AUClast,\nDependent on the least-squares fit: Lamda Z, AUC 0-inf, %Extrapolation, terminal half-life, volume, clearance\n\n\n\n1.4.6 Volume of Distribution\n\\[\nC = \\frac{Dose}{V}\n\\]\n\nvolume of distribution relates to the dose and concentration\nDoes not corresponds to anything physiological\nExample, 100 ug dose to IV bolus and 2 ug/L concentration, volume is 50L.\ntypical human plasma volume is 5 L, why V is sometimes very large?\nDrugs that are strongly bound to protein has very high V\n\n\n\n1.4.7 Clearance\n\nClearance Quantifies how quickly drug is removed from the body\n\n\\[\nRate of elimination = Cl * C(t)\n\\]\n\nIn most cases Cl is constant. If changes with concentration, suspect non linear kinetics (saturation). for this reason, different dose level is adminstered.\nClearance includes both Metabolisma and Excretion\n\n\n\n\nit is difficult to obtain all the ratios, so the overall ratio is called Bioavailability.\n\nBioavailability\n\\[\nF = \\frac{AUC_{oral}/Dose_{oral}}{AUC_{IV}/Dose_{IV}}\n\\]\n\nIntravenous: NCA parameters are V and Cl (F = 1)\nExtravascular: NCA parameters are V/F and Cl/F (F<1)\nElimination = Metabolism (liver) + Excretion (Kidney)\nCltotal = Clhepatic + Clrenal + Clother\nClrenal = Ae (amount of drug excreted in the urine)/ AUCplasma\nCalculation of Clearance from NCA:\n\n\n\nYou get the following from NCA\n\n\n\n\n1.4.8 Linear vs Log"
  },
  {
    "objectID": "WinNonlinIntro.html#run-nca-on-plasma-data",
    "href": "WinNonlinIntro.html#run-nca-on-plasma-data",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.5 Run NCA on Plasma Data",
    "text": "1.5 Run NCA on Plasma Data\n\n1.5.1 Run NCA using best fit\n\nDrug: Gravitix, 10 subjects, a single ascending dose (SAD) study, 6 dose level (1, 2, 4, 8, 16, 32 mg), PO adminsitration\nFrom the plot each subject grouped by dose level, we see that as the dose increases so do the concentrations in plasma\nwe expect that the drug exposure should increase proportionally to the dose\nafter we run NCA we will assess dose proportionality by examining PK parameters returned by NCA\nTwo worksheets: Observations and Dosing. Data on Observatino worksheet: Conc, Time, Subject, Doselevel, Administration, Amount.\n\nPerforming NCA:\n\nRight click on observation worksheet\nselect sent to, non-compartmental analysis, NCA\nSelect plasma, which is default setting\nspecify the dose type the default is extravascular\napply the main mappings\nthe time is already mapped\nmap the conc to concentration\nmap subject to sort\nmap doselevel to sort\nselect dosing. two options: a worksheet with the dozing information or an internal worksheet\nselect source\nclick okay\nTime is already mapped\nmap amount to dose\nmap subject and dose level to sort\nspecify the calculation method linear up logdown\nclick execute\ndouble click the final parameters pivoted worksheet to open in its own window\n\nViewing plots:\n\nselect observed y and predicted y versus x\nfor subject one dose level 1: 5 points were used in the \\(\\lambda_Z\\) calculation, from 8 hours to the last observation at 36 hours\nThe best fit method automatically determines the optimal least squares regression using at least three points\nr-squared is the correlation coefficient of the regression\nr squared adjusted is based on the r squared adjusted for the number of points in the regression\nThe number points with the best value of r squared adjusted is used.\nthe half-life based on the value of \\(\\lambda_Z\\) is also reported in this case the half life is about 22 hours\nPage 2: this plot is also for subject one but now the dose level is 2 mg\nin this case the best fit method used three points in the calculation\neven though it is the same subject but the half-life based on lambda z is much shorter than for the first dose at only about 15 hours\nPage 3: this plot is for subject one does level 4\nagain 3 points were used in the calculation\nthe half-life is about 28 hours\nPage 4: this is for subject one those level 8\nthis time five points were used in the half-life is 15 hours\nPage 5: now we are up to those level 16 for and half-life is 21 hours\nPage 6: this plot is now at the highest to those level 32 mg\nthe half life is lower this time It’s 18\nwe have seen it’s quite a variability between different dose levels but is there a systematic trend?\n\nlet’s create a box plot to see if there is appears to be a trend\n\nright click on final parameters pivoted\nsend to plotting: box plot\nmap HL_lambda_z to y\nnow we want to look for a trend across the dose group map to dose level\nclick execute button\nThe plot shows us the distribution of half-life across the different dose groups\nfrom the plots we can see that although there is a good deal of variation in the dose levels, there does not appear to be a systemic trend and all the boxes overlopped with each other\n\nBox plot of AUCs\n\nlet’s make the duplicate of this plot:\nright click box plot\nselect copy\nright click on the workflow\nselect paste\nselect the duplicated plot let’s change the mapping for the y map AUCINF_D_obs\nclick execute\nbecause the data are dose normalized AUC values extrapolated to infinity we would expect these values to be the same for all dose groups and they do appear to be very consistent\nmost values falling between 0.04 and 0.05\nthis does suggest that the overall drug exposure is proportional to the dose\nalthough this is not a statistical test for the dose proportionality, it does give us a quick visual impression\n\nBox plot of AUClast_D\n\nLet’s make duplicate of the second plot right click the plot select copy right click on workflow paste\nmap AUClast_D to y execute\n\n\n\n1.5.2 Customize rules and parameters\n\nGoal is to add \\(\\lambda_Z\\) acceptance rules to our NCA\nselect the rules tab\nenter 0.9 for r-squared adjusted\nenter 20 for percentage of extrapolation\nenter 2 for span, the span is the number of half lives spent by the regression.\nclick execute\nReview the flag column for r-squared adjusted, % extrapolation and span\nnote that the results are not removed from the output\nbut we can use data tools to do the filtering if we want to\n\nTo filter the data:\n\nRight click in the final parameters pivoted worksheet\nSelect sent to\nselect data management\nselect split worksheet\nmap the three flag columns to sort\nClick execute\n\nThe “unique values” worksheet shows how many rows there are for each combination of sort values - notice that there are 24 rows that passed all criteria\n\nlet’s look at the worksheet fully accepted here we see the walls that has all three criteria is\n\nUser defined parameters\n\nselect “user defined parameters” tab\nto compute the concentration at a time of 48 hours\ninter 48 in the box The other thing that we can do is user defined parameters\nthe NCA does include many parameters we can also define our own\nclick add button\nadd a parameter, i.e., AUC_2\nFor definition you see last / 2\nif you would like this values include in the final parameters pivoted worksheet turn on include the final parameters\nexecute the NCA object\n\n\n\n1.5.3 Customize slope selections\n\nstart with NCA used in previous section\nDuplicate the NCA object\nselect slopes selector from the Setup trab\nEach plot is on a separate page, on each plot we can see the points that were used select for best fit.\nclick the left point to change starting point for the linear fit\nto change the end of the fitting, holding down the shift key and clicking on the indicated point\nDon’t change the endpoint of the fitting unless you have reason to reset the last point\nto exclude points from the linear fit hold on the control key and click on the indicated point\n\nFaster way of modifying slopes:\n\nselect the slopes under the Setup tab\nthis worksheet has the same information we saw in the individual plots but all on one table\nto control the best fit method select rules tab\nwe have two options for customizing you can either limit the number of points used in the linear regression or you can specify your start time limit\nSince there is a distribution phase we might decide to make sure that we do not include from the 12 hours in linear regression\ntype of 12 in the option start not before\nlet’s look at the slopes and then see output settings\nselect slope settings\nNow, the start time is at least 12 hours\nComparing box plots from two NCA results ( best fit and coustom fit) it is seen that some of the outliers are removed.\nIt is good idea to examine each slopes and adjust the solpes to compare the data.\n\n\n\n1.5.4 Compute partial areas\nIn the previous section we saw how comparing AUClast was problematic.When different subjects had different Tlast, Computing partial areas is a way that can overcome that limitation.\n\n\nSelect the setup tab\nSelect Partial Areas\nCheck “use Internal Wroksheet”\nBeacause we will use the same partial areas for all subjects, uncheck subject checkbox and beacause we want to use the same settings for all dose groups, uncheck DoseLevel checkbox\nClick OK\nWe may want to compute more than one partial area, at the bottom of the option tab, we can specify how many we want.\nClick on the selector for number of maximum partial areas. Select 2\nOnce again, we are asked to specify the sorts, Uncheck subject and dose level checkbox.\nWe need to fill in the start and end times\nFor the first partial area, we will compute the partial area for the first 12 hours\nSpecify 0 for the start time and 12 for the end time.\nFor our second partial area, use 0 and 24 hours.\nIf desired, we can label for each partial area. However, label is not required and it will automatically generate for us. Leave the label field blank.\nClick Execute.\n\nThe partial areas are added as columns to the right of the final parameters pivoted.\nLet’s repeat the process for other NCA object in our project: Select NCA best fit Click Setup Click Partial Areas Check “Use Internal Worksheet”\nTurn off Subject and doselevel Specify the maximum number of partial areas\nThe plots are all read, because the plots are all out of date -WE can update by Selecting the workflow in the object browser, the Workflow is displayed, click the Execute butte and it will update. While the Workflow is selected, on the result tab, we have the output of the workflow. Let’s go back to the workflow diagram, select Diagram, notice how the red color gone\n\n\n1.5.5 Use Theraputic response\nTo choose a dose for a given drug we have consider both the efficacy and side effects. We can set upper and lower concentration limits in NCA and quantify the time and AUC between the limits as well as above and below.\n\nThe following plot is for gravitex SAD study: Let’s say we want concentration to be between 10 and 50 ug/L. At the lowest dose, all the concentrations are below the lower limit. For higher dose (32 mg), concentrations are largley between the upper and lower limit\n\nSelect “Therapeutic Response” option on the Setup tab of the NCA object\nuncheck both subject and dose boxes\nEnter 10 for lower limit and 50 for higher limit\nExecute\n\n\n\n1.5.6 Customize units and parameters names\nTo obtain units in the NCA results, we need to have units defined on the concentrations, the times and the doses\n\nconcentration units are microgram per liter, nanogram per liter and micromols per liter\ntimes units are typically either hours or minutes and in some cases days\nunits for doses are milligrams micrograms and micromols\nit is not recommended to mix mass units\nif you get no units on your results you may have missed the unit on the concentration, time or dose, you will see the message insufficient unit in the units output. If this happens to you check that you have proper units on the concentration time and dose\n\nDefine the units used in the NCA:\n\nselect the setup tab\nselect the units input\nThe default units depend on input dataset units because the time units in the input data set is hours all the time units in the NCA results will also be based on hours\nThe volume unit in our input data is liters and therefore all the results have liters in the default units\nif we decide we want to change the units on our results we can do so by changing the values in the columns labeled preferred\n\nlet’s do that\n\n\nChange the preferred unit for volume to milliliter\nspecify milliliters per minute for the clearance unit\nMake sure to match the case as shown\nPhoenix will attempt to convert but if Phoenix doesn’t know how to convert to your preferred unit it will revert to the default unit execute the NCA\nBy checking execute here you can see the appropriate units in the results.\n\nChanging Parameters Name\n\nClick setup tab select the parameter names input\nTurn on the Use internal worksheet checkbox\nLet’s say that we want to change the name of half life\nAnd executed the NCA and now the half-life column has been renamed in the result"
  },
  {
    "objectID": "WinNonlinIntro.html#run-urine-nca",
    "href": "WinNonlinIntro.html#run-urine-nca",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.6 Run Urine NCA",
    "text": "1.6 Run Urine NCA\n\n1.6.1 About Urine NCA\n\n\nUrine samples are collected over an interval. Four samples were collected and concentration and volume was measured, the data is compiled in the table.\nThe rate of drug excretion is calculated by:\n\n\\[\nRate = \\frac{A_{ur}}{t_{end}-t_{start}}\n\\]\n\nPlot the Rate of drug excretion vs midpoint of collection interval\nRate of excretion starts high and decreases over time.\n\n\n\nMost import parameters are Amount Recovered and Percent Recovered and Percent of extrapolation (AURC_%Extrap_red)\nUrine NCA also include lambdaZ and halflife, however, since the urine data only contains four data, it is better to use plasma halflife\nPercent of extrapolation should be as small as possible.\n\n\n\n1.6.2 Setup project\n\n10 subjects, dose level, 4 mg, conc in both plasma and urine,\n\n\n\n1.6.3 Exploratory Data Analysis\n\nXY plot of plasma conc vs time is created\nXY plot of urine conc vs time is created. Time is end of collection interval\n\n\n\n1.6.4 NCA of plasma data\n\nmap x to Time, y to conc, sort to subject\nselect the Dosing imput, map Time to Time, Dose to dose, sort to subject\nSelect linear up log down\nExcecute\n\n\n\n1.6.5 NCA of urine data\n\nspecify the model type: Urine\nRequired mapping: start time, end time, concentration, volume\nsort to subject\nselect the dosing file, sort subject\nExecute\nAutomatic data calculations was done. Three different rates are given: Max_rate, Rate_last, Rate_last_pred, Tmax_rate, AURC: Area Under the Rate Curve\nUrine NCA does not extrapolate for amount recovered and percent recovered. That’s why it is best to collect urine samples until no more drugs are detected in the urine sample\n\n\n\n1.6.6 Calculate Renal Clearance\n\n\nright click Final Parameter Pivited, send to “computation tools”, “ratio and differences”.\nmap sort to subject\nSelect the worksheet2 input, click to select source button, select “Final Parameter Pivited” from NCA plasma, sort to subject\nOn the options tab, update the X column to “Amount Recovered”, Y column: AUClast, new column name: Clr, unit: L/h,\nExecute\n\nCreate a box plot\n\nRight click Ratios Differences Stacked, send to box plot, map y to Clr,"
  },
  {
    "objectID": "WinNonlinIntro.html#sparse-and-steady-state-nca",
    "href": "WinNonlinIntro.html#sparse-and-steady-state-nca",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.7 Sparse and Steady-State NCA",
    "text": "1.7 Sparse and Steady-State NCA\n\npreclinical study of Gravitex in rats, 20 rats, dose: 200 ug/kg,time of blood draws: group A(0.5, 1, 2, 4, 8 h), group B( 0.75, 2, 6, 12 h)\nNot possible to do full NCA with only four data points\nWe need to pool the data to do NCA\nData: Schedule ( group A or group B), Animal, Time, Conc\n\n\n1.7.1 EDA of Sparse Data\nCreate a plot Concentration vs time by schedule\n\nPlotting the data: XY plot, map x to Time, y to conc, group to schedule, group to animal\nOptions pan, select the graph Conc vs Time, select Quick Style tab, check “Each group to color”, select “Schedule”\nNow the lines are yellow for group A and purple for group B.\nTurn off “group by marker”, now all the markers are same\nTurn off “group by lines”,\nSelect the Legend and turn off the “visible” checkbox\n\nReporting as concentrations table\n\nright click observation worksheet, send to reporting, select table\nmap conc to Data, animal to Raw ID, Raw Stratification to Schedule, Column Stratification to Time.\nSelect “Precision/Alignment” from option, precision method: significantDigits, value: 3,\nFor Time, specify the precision method: DecimalPlaces, value: 2, execute\nSelect Animal column, specify precision method: DcimalPlaces, value: 0\nSelect statistic tab, turn of “mean” and “SD”\n\n\n\n1.7.2 NCA of Sparse Data\n\n\nSend the data to NCA, turn on “Sparse” button\nRequired mapping: Time to time, Concentration to Conc and Subject to Animal\nSpecify dosing file, time to Time and dose to dose_norm, execute\nThere is only one raw in the result sheet\nLinear Trapizoid method was used and SE was obtained for some of the PK parameters.\nSince the data is pooled, only one plot is obtained.\n\n\n\n1.7.3 EDA of Multiple-Dose Data\nStudy design of Gravitex multiple dose study\n20 human subjects randomly divided into two groups (dose level 2 and 4), dosed at 0h, conc determined at 48 h,2nd dose at 48h, next doses at every 24h, until 192 hours. The first dose is a Naive dose\n\nRichly sampled for 0 to 48 hours and the last dose from 192h to 240h. Only Trough conc were measured for other doses\n\n\nBlue lines are generated from PK model.\n\nplot the data by mapping x to Time, y to Conc, group to subject, lattice page to dose level, lattice column to profile\n\n\nAfter modifying x and y axis:\n\nMaking a Table\n\nSend to reporting, Table\nmap Data to Conc, subject to RowID, dose level to stratification row, stratification column to time, profile to stratification column.\nSelect Column/sort Order, select Row Stratification, select Column Stratification, move profile to the top,\n\n\n\n\n1.7.4 Split Data\n\nBefore running NCA of multiple dose data, we need to split data\nRight click the worksheet, send to Data Management, Split Worksheet\nmap profile to sort, Exicute.\nSplit the dose worksheet the same way as the observation worksheet\n\n\n\n1.7.5 NCA for First Dose\n\nSelect Split Observation, right click on Output data A, send to NCA\nmap subject to sort, dose level to sort, conc to concentration, time to Time\nlink dosing input for A profile\nmap Dose to Amount, Tau to Tau, sort to dose level and subject\nCalculation method LinearupLogdown\nSelect Dose level column and click freez pane icon\n\n\n\n1.7.6 NCA for Final Dose\n\nperform same operation as for First Dose by selecting profile C.\nTmin is the time where minimum concentration was found\nCtau is the concentration at the end of the dosing enterval\nCavg is the average concentration during the dosing interval\nDifference between AUClast and AUCtau\nSlope correction of the linear fit is of concern only if we are extrapolating the results. Otherwise AUCtau will not be affected by the slope correction.\n\n\n\n1.7.7 Determine Accumulation Ratio\n\nNCA can only determine PK parameters of the first dose or the last dose,\n\npartial area"
  },
  {
    "objectID": "WinNonlinIntro.html#use-data-tools",
    "href": "WinNonlinIntro.html#use-data-tools",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.8 Use Data Tools",
    "text": "1.8 Use Data Tools\n\n1.8.1 Append Worksheets\n\nCombine data from two worksheets that share the same general structure of columns\n\n\n\nexample, combine PK1 and PK2. The new column “source” tells which worksheet each set of rows came from.\nColumns do not have to be identical nor the same order\nRight click the worksheet, select Data Management, Append Worksheets\nmap source column to all the columns of worksheet 1\nClick worksheet2, link the source file, map all the columns to Source Column\nDouble click Results tab to view the results\nTo append more that one worksheet, set the number on the option section\n\n\n\n1.8.2 Crossproduct Worksheets\n\nFor making combination of multiple columns,\n\n\n\nRight click the worksheet, send to Crossproduct Worksheet\nmap subject to sort\nLink the second worksheet and map the same way as before, Execute\n\n\n\n1.8.3 Join Worksheets\n\nTo combine data so that rows are matched by a common sort key. Merge option is identical to Join option.\n\n\n\n\n\nboth column has be to same name to join the columns.\nClick ’sort map”, turn on Internal Worksheet, cut and paste to the same row.\n\n\n\n\n1.8.4 Pivot Worksheet\n\nRearranging data to allow comparison, for example to compare the effect of treatment, we need to see the data:\n\n\n\n\n\n\n1.8.5 Stack Columns\n\nInverse of Pivoting . Stackers stacks two or more column into a single column\n\n\n\nChange the column names from the options section\n\n\n\n\n1.8.6 Split Worksheet\n\n\n1.8.7 Enumerate Worksheet\n\nTo convert text values to numbers,\n\n\n\n\n\n1.8.8 Make BQL Substitutions\n\n\nAny non-numeric data is ignored by the NCA object\n\nTo estimate Tlag we must replace BQL by zero"
  },
  {
    "objectID": "WinNonlinIntro.html#compute-ratios-and-differences",
    "href": "WinNonlinIntro.html#compute-ratios-and-differences",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.9 Compute Ratios and Differences",
    "text": "1.9 Compute Ratios and Differences\n\n1.9.1 Compute Ratios from Single Input\n\n10 subjects with 2 mg IV dose, after wash out period same subject was administered 4 mg PO, To compute Bio-availability, we need to do ratio from a single worksheet.\n\n\n\n\n\n1.9.2 Compute Ratios from Dual Inputs\n\nNCA for urine and plasma must be done in separate NCA object, we have to combine results from two different worksheets.\nRenal Clearance example, view clearance section above.\n\n\n\n\n1.9.3 Compute Ratios using Means\n\nDifference between cross-over and parallel study\n\n\n\n\n\n\n1.9.4 Compute Differences"
  },
  {
    "objectID": "WinNonlinIntro.html#use-data-wizard",
    "href": "WinNonlinIntro.html#use-data-wizard",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.10 Use Data Wizard",
    "text": "1.10 Use Data Wizard\n\n1.10.1 Create a Filter\n\nFilter by time values\nRight click, send to Data management, Data Wizard ### Set Column Properties\n\n\n\nWe can: 1. Exclude whole column; 2. Exclude or include by values, 3. Filter individual cells or whole rows.\n\n\n\n1.10.2 Set column properties\n\nThis can be used to sort columns, rename columns, specify or convert units\n\n\n\n1.10.3 Transform Data (Arithmatic)\n\nused to do simple arethmatic; x and y are variables, n is constant, units inherited from source.\nsame as data normalization.\nSet baseline in Time based data, Requires Time and Data Columns to map, Substrat the initial values\n\n\n\n1.10.4 Transform Data (Custom)\n\nCeiling, random\n\n\n\n\n1.10.5 Transform Data (Functinos)\n\nthis works with only on single column such as X to Ln(X).\n\n\n\n1.10.6 Multi-step operation"
  },
  {
    "objectID": "WinNonlinIntro.html#applications-of-nca",
    "href": "WinNonlinIntro.html#applications-of-nca",
    "title": "1  Introduction to WinNonlin (122-D)",
    "section": "1.11 Applications of NCA",
    "text": "1.11 Applications of NCA\n\n1.11.1 Using Cmax and AUC to Make Decisions\n\n\n\n\n\n1.11.2 Study Designs\n\n\n1.11.3 Dose Proportionality\n\n\n\n1.11.4 Average Bioequivalence\n\n\n1.11.5 Food Effects\n\n\n1.11.6 Drug-Drug Interactions"
  },
  {
    "objectID": "WinNonlinModel.html#what-is-a-model",
    "href": "WinNonlinModel.html#what-is-a-model",
    "title": "2  WinNonlin Modeling(123-OD)",
    "section": "2.1 What is a Model",
    "text": "2.1 What is a Model\n\na mathematical abstraction\nbelow is a diagram of a typical PK model\n\n- The movement of drug through the body is usually much more complicated than depicted in the diagram but even a simple model such as this can mimic the shape of the observed data and allow us to make predictions.\n\nmodels can be anywhere from purely empirical to purely mechanistic\n\nempirical model is used just because it fits the data without drawing too many conclusions about the process that the drug undergoes while being absorbed distributed metabolized and eliminated\na mechanistic model accounts for many of the processes that the drug is known to undergo\nthe model in the diagram is translated into a series of differential equations\n\nThe equations that describe the model are converted into model code in Phoenix\nParameter values"
  },
  {
    "objectID": "WinNonlinModel.html#parameterization",
    "href": "WinNonlinModel.html#parameterization",
    "title": "2  WinNonlin Modeling(123-OD)",
    "section": "2.2 Parameterization",
    "text": "2.2 Parameterization\n\nparameterization refers to the type of parameters that are used in the model\nexamples include clearance parameters, micro parameters and macro parameters\n\nlet’s see how these differ first let’s consider\nclearance parameters\n\nthe most widely used\nThe parameters in this model are the absorption rate constant, the clearance and the volume\nwe suggest using clearance parameters when possible because\n\nclearances are physiologically relevant and\nclearance-based models tend to be more stable\nit is also easy to obtain initial estimates by using parameters from NCA\n\n\nmicro-parameters\n\nAll the transport is defined in terms of rate constants\nThese models are also widely used particularly for more mechanistic\nIn the picture model both KA and Ke are rate constants and v is the volume\n\nmacro parameter\n\nThese were the first type of parameters to be used in PK modeling\nPK curve is given by an equation that is combination of one or more exponentials\nthese parameters are not directly related to the phyiology\n\nClearance paremeters and microparameters are easily convertable. Let’s look at the\nFirts, let’s consider microparameters:\n\n- drug can move in both direction k: rate constants A ;amount of drug in the originative compartment\nNext the clearance parameters \nClearance and microcompartment models are usually equivalent and gives similar results. However, clearance models are more commonly used.\n\n\n2.2.1 administration\nthe way the drug is administered has a large effect on the shape of the PK curve. three types of administration\n\nExtravascular\n\n\nOral, subcautaneous, intervanious, etc any kind of administration that involves an absorption\nthere is a depot compartment that receives the dose\nin Phoenix the dose point is indicated with the blue syringe, The name of the absorption compartment is AA and the absorption rate constant is KA any administration\n\n\nIntravenous (IV infusion or IV bolus)\n\n\nDelivered at a constant rate for a defined duration or rate\nthere is no absorption process and the dose point delivers the drug directly into the central compartment\n\nlet’s compare the shapes of PK curves resulting from different administration methods here are three simulations all with - a dose of 5,000 micrograms - a volume of 100 liters - a clearance of 20 liters per hour and - an absorption rate constant ka of 1 per hour\n\n\n\n\nthe elimination phase is linear in all three plots and there is no distribution phase seen"
  },
  {
    "objectID": "WinNonlinModel.html#model-structure",
    "href": "WinNonlinModel.html#model-structure",
    "title": "2  WinNonlin Modeling(123-OD)",
    "section": "2.3 4. model structure",
    "text": "2.3 4. model structure\n\nthe model structure affects the shape of the pK profile\nthree different aspects of model structure\n\nnumber of compartments\npresence or absence of a time lag\nsaturating elimination\n\n\nThe effect of the number of compartments:\none compartment model is the simplest\n\none compartment extravascular model\nhas three parameters k a v and CL\n\nTwo comartment models adds a peripheral compartment which can take up some of the drug - needed when there is a sizable distribution phase - five parameters\nthree compartments - adds two more parameters V3 and CL3 - The three compartment model is not used frequently \nshape but the PK curve\n - one compartment IV bolus model is just a straight line when plotted on a log concentration axis - a two compartment model is useful when there is a distribution phase that is different than the elimination phase - The three compartment model can have three distinct phases - it will not always be as apparent that there are multiple phases instead of two distinct phases we may see a general curvature that blends two or more phases together\ncorresponding extravascular Administration but\n - Early distribution phases can become obscured because of the absorption phase - this is particularly apparent in the three compartment model where the first distribution phase is entirely obscured by the absorption\ntime lag\nmany drugs take some time to show up in systemic circulation and the time lag is a way that we can account for this in our model\non the left is a model with the time lag and on the right is the corresponding model without a time lag T-Lag is a parameter that causes the absorption to be delayed Time lag has the same time units as the time column\n\nadd a time lag to your model if tmax does not fit properly\nThe model fit can then adjust both the KA and the T-Lag values to obtain and improve fit\n\nsaturation\n\nlinear elimination saturation is often referred to as Michaela\nreplaces clearance parameter with Km and Vmax  Clearance is no longer constant Clearance is depended on the concengtratino downward bend is characteristics of saturating kinetics saturation increased with higher doses\n Let’s see how this change affects the shape of the PK curve click next to continue  here are simulated curves for a drug that has a KM value of 1,000 in a saturating model clearance becomes the expression v max over km + c this means that clearance depends on the concentration and the clearance is no longer constant notice how different doses have PK curves with dramatically different shapes notice how many of the curves have a downward bend this downward bend is a characteristic of saturating kinetics it may not be observed at lower doses but as the dose increases we may encounter saturation and it is useful to know what it looks like at the lowest dose shown here the yellow curve looks just like a one compartment model with linear kinetics as the dose increases we see more saturation notice how\nwhen the concentration is higher than the KM value the apparent clearance is much lower and the slopes are much shallower at higher concentrations scale\nThis breakdown the dose proportionality\n\nLinear scale:\n\nThe increase in AUC is far beyond what we would have predicted under linear kinetics\nIn cases were saturation is observed it is important to have data from more than one dose amount so that you can obtain in reliable parameter estimates\n\n\n if we consider the expression for the effective clearance at different concentrations we can consider two extremes when the concentration is much lower than the KM value we do not see any saturation and the clearance is constant clearance over KM at the other extreme when the concentration is much greater than the KM value The clearance reduces to VMAX over c as the concentration increases the clearance becomes progressively smaller at very high concentrations we are overwhelming the elimination pathway usually this happens when an enzyme has a finite capacity to eliminate the drug and we are overloading it you may never need to create a model with saturating elimination but it is good to know when to recognize that saturation\nlet’s recap the section we have seen that the model structure is typically defined by the number of compartments the presence or absence of a time lag and the possibility of saturating elimination These three items can be combined to make a very large number of potential models click next to continue"
  },
  {
    "objectID": "WinNonlinModel.html#residual-error",
    "href": "WinNonlinModel.html#residual-error",
    "title": "2  WinNonlin Modeling(123-OD)",
    "section": "2.4 5. residual error",
    "text": "2.4 5. residual error\nResidual error:the difference between the observed and predicted concentrations DV: dependent variable or observed concentration\nIPRED: Individual prediction, the predicted concentration\n\n\n\nresdials\n\n\nideal prediction would fall on the line positive residual error negative residual error\nLet’s look at another type of plot that is more useful for examining the residuals click next to continue\n\nThese plots show us the residuals on the y-axis with either the predicted concentration or the time on the x-axis\neach point is a residual error\nboth plots have the same number of points they’re just arranged differently\nThe dotted lines represent two standard deviations in the positive and negative directions\n\n\nResidual worksheet contains the data that was plotted Ires: individual residual, difference between DV and IPRED\ndifferent methods for the residual error - additive : assumes that all errors are constant regardless of concentration . In practice we usually find that the error magnitude becomes smaller at smaller concentrations and therefore additive is not often the best choice - multiplicative, assumes that the errors are proportional to the concentration of - additive plus multiplicative: partly constant, partly proportional. at higher concentrations the error magnitude is proportional but at small concentrations the error reaches a threshold and does not decrease any more as the concentration falls\nUse multiplicative the initial choice of residual error when building models\nStart your modeling using a multiplicative residual error as you are optimizing the structural model - after you have decided on the best structural model then you can start optimizing the residual error model\n\n\n\n\nAlam, Muhammad. 2006. “Geometry of Diffusion and the Performance Limits of Nanobiosensors.”"
  },
  {
    "objectID": "summary.html#pk-model-1",
    "href": "summary.html#pk-model-1",
    "title": "3  Summary",
    "section": "3.1 pk model 1",
    "text": "3.1 pk model 1\n\n3.1.1 Concentrations should be stacked\ndata format for PK models - observed concentration stacked into a single column - multiple analytes or metabolites concentration should be its own column\n \nSort variables\n\nFor multiple PK profiles, one or more sort variables are required.\nSort variables need to have a value on every row\nIn Phoenix text values, blank cells are not a problem\nAll non-numeric data is ignored by the model\n\n\n\namount oral column has a value at time zero and the rest of the rows are blank. The dose amount is given only on the row the corresponds to a dosing event\ndose level column has a value on every row\nunits: unlike NCA the model object does not translate units\n\nThe dose unit should always be the same as the unit in the concentration\n\nAnd your parameter values keep them the same so that the units will work out properly One more warning the model object allows you to either map the dosing amounts in the main input or the dosing input Make sure that you don’t map the dose amount in both places or your administered dose will be twice as large as you intended click next to continue let’s recap the section we saw how the model object requires stacked concentrations you should have a single concentration column for each observation second we use sort variables to define the individual PK profiles there’s nothing wrong with having more sort variables than you need third we saw how dosing events can be included in the data set remember that these are entered on the row at the time of the dosing event and finally we learned that text values and empty cells are okay in the input and we do not have to do anything to them this completes the section click"
  },
  {
    "objectID": "TechNotes.html#pbpk-notes",
    "href": "TechNotes.html#pbpk-notes",
    "title": "4  My Tech Notes",
    "section": "4.1 PBPK notes",
    "text": "4.1 PBPK notes\nhttps://www.admescope.com/whats-new/blog/2016/pbpk-what-it-is-for"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alam, Muhammad. 2006. “Geometry of Diffusion and the Performance\nLimits of Nanobiosensors.”"
  }
]